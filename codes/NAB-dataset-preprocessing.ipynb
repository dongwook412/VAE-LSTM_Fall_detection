{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"NAB-dataset-preprocessing.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TV8GsvPth8sw","executionInfo":{"status":"ok","timestamp":1623763825934,"user_tz":-540,"elapsed":265,"user":{"displayName":"황보성훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQv-AFTIUw9GfCGLfL0KckPa-e7rFWhGt5tF78rQ=s64","userId":"05629785583952416700"}},"outputId":"257a2f08-11a5-4f1a-b76a-6218c43cd968"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WXnN-oz6hbhg"},"source":["import os\n","import csv\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pylab as plt\n","from matplotlib.pyplot import plot, ion, show, savefig, cla, figure"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U8apabaM5qQv"},"source":["## 아래 코드는 colab에서 실행하면 오래 걸려서 데스크탑으로 진행"]},{"cell_type":"code","metadata":{"id":"YS085YEyjaM0"},"source":["# Data_preprocessing.py 파일로 실행\n","'''\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","train_path = 'C:/Users/thehb/OneDrive/Desktop/성훈_석사/수업/고급시계열/프로젝트/VAE-LSTM-for-anomaly-detection/datasets/NAB-known-anomaly/csv-files/fall_data/train'\n","test_path = 'C:/Users/thehb/OneDrive/Desktop/성훈_석사/수업/고급시계열/프로젝트/VAE-LSTM-for-anomaly-detection/datasets/NAB-known-anomaly/csv-files/fall_data/test'\n","\n","file_list = []\n","train_file_list = os.listdir(train_path)\n","test_file_list = os.listdir(test_path)\n","for file in train_file_list:\n","    file_list.append(os.path.abspath(train_path+'/'+file))\n","for file in test_file_list:\n","    file_list.append(os.path.abspath(test_path+'/'+file))\n","\n","\n","all_data = []\n","all_label = []\n","window_size = 10 # 0.05초\n","#size = 0\n","for file_dir in file_list:\n","    print(file_dir)\n","    df = pd.read_csv(file_dir, usecols=['gyro_z', 'label'])   \n","    #size += len(df)\n","    df.loc[(df.label == 'FOL'), 'label'] = 1\n","    df.loc[(df.label == 'FKL'), 'label'] = 1\n","    df.loc[(df.label == 'BSC'), 'label'] = 1\n","    df.loc[(df.label == 'SDL'), 'label'] = 1\n","    df.loc[(df.label != 1), 'label'] = 0\n","    data = np.array(df.gyro_z)\n","    label = np.array(df.label)\n","    for i in range(len(data) // window_size):        \n","        all_data.append(np.mean(data[i*window_size:i*window_size+window_size]))\n","        all_label.append(0 if np.sum(label[i*window_size:i*window_size+window_size]) < 5 else 1)\n","#print(size)\n","len(all_data)\n","\n","pd.DataFrame(all_data, columns=['values']).to_csv('C:/Users/thehb/OneDrive/Desktop/성훈_석사/수업/고급시계열/프로젝트/data/fall_gyro_z.csv', header= True, index=True)\n","pd.DataFrame(all_label, columns=['label']).to_csv('C:/Users/thehb/OneDrive/Desktop/성훈_석사/수업/고급시계열/프로젝트/data/fall_label.csv', header= True, index=True)\n","\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6jGU4qvKhbhk"},"source":["## Helper functions to load and process original csv files"]},{"cell_type":"code","metadata":{"id":"O5-iV2Srhbhk"},"source":["# this function load one .cvs (a sequence)\n","def load_data(csv_folder='/content/drive/MyDrive/Colab Notebooks/Timeseries/Team_project/VAE-LSTM-for-anomaly-detection/datasets/NAB-known-anomaly/csv-files/'):\n","    '''\n","    [input]\n","    dataset: 파일명\n","    csv_folder: csv 파일이 위치한 폴더명\n","\n","    [return]\n","    t: idx 모음\n","    t_unit: 데이터 간의 시간 간격\n","    readings: 데이터\n","    idx_anomaly: anomaly에 해당하는 idx\n","    '''\n","    # train/val dataset\n","    #data_file = os.path.join(csv_folder, 'fall_gyro_z.csv')\n","    #label_file = os.path.join(csv_folder, 'fall_label.csv')\n","    \n","    # test dataset\n","    data_file = os.path.join(csv_folder, 'test_fall_gyro_z.csv')\n","    label_file = os.path.join(csv_folder, 'test_fall_label.csv')\n","    \n","    t_unit = '0.05 sec'\n","    \n","    t = []\n","    readings = []\n","    idx_anomaly = []\n","    with open(data_file) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        print(\"\\n--> Anomalies occur at:\")\n","        for i, row in enumerate(readCSV):\n","            if i > 0:\n","                t.append(i)\n","                readings.append(float(row[1]))\n","                '''\n","                for j in range(len(anomalies)):\n","                    if row[0] == anomalies[j]:\n","                        idx_anomaly.append(i)\n","                        print(\"  timestamp #{}: {}\".format(j, row[0]))\n","                '''\n","    \n","    with open(label_file) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        for i, row in enumerate(readCSV):\n","            if i > 0:\n","                if row[1] == '1':\n","                    idx_anomaly.append(int(row[0]))\n","    t = np.asarray(t)\n","    readings = np.asarray(readings)\n","    print(\"\\nOriginal csv file contains {} timestamps.\".format(t.shape))\n","    print(\"Processed time series contain {} readings.\".format(readings.shape))\n","    print(\"Anomaly indices are {}\".format(idx_anomaly))\n","    \n","    return t, t_unit, readings, idx_anomaly"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXazefP4hbhm"},"source":["# This function plots a dataset with the train/test split and known anomalies\n","# Relies on helper function load_data()\n","\n","def process_and_save_specified_dataset(dataset, idx_split, y_scale=20, save_file=False):\n","    '''\n","    [input]\n","    dataset: csv 파일명\n","    idx_split: train 데이터에 해당하는 idx 구간(나머지 뒷부분은 test로 사용됨)\n","\n","    [return]\n","    t: 전체 데이터 idx\n","    readings_normalised: 정규화된 readings(데이터)\n","    '''\n","    t, t_unit, readings, idx_anomaly = load_data()\n","    \n","    # split into training and test sets\n","    training = readings[idx_split[0]:idx_split[1]]\n","    t_train = t[idx_split[0]:idx_split[1]]\n","    \n","    # normalise by training mean and std \n","    train_m = np.mean(training)\n","    train_std = np.std(training)\n","    print(\"\\nTraining set mean is {}\".format(train_m))\n","    print(\"Training set std is {}\".format(train_std))\n","    readings_normalised = (readings - train_m) / train_std\n","    \n","    training = readings_normalised[idx_split[0]:idx_split[1]]\n","    if idx_split[0] == 0:\n","        test = readings_normalised[idx_split[1]:]\n","        t_test = t[idx_split[1]:] - idx_split[1]\n","        idx_anomaly_test = np.asarray(idx_anomaly) - idx_split[1] # anomaly data는 test에만 있다고 정의했나봄\n","    else:\n","        test = [readings_normalised[:idx_split[0]], readings_normalised[idx_split[1]:]]\n","        t_test = [t[:idx_split[0]], t[idx_split[1]:] - idx_split[1]]\n","        idx_anomaly_split = np.squeeze(np.argwhere(np.asarray(idx_anomaly)>idx_split[0]))\n","        idx_anomaly_test = [np.asarray(idx_anomaly[:idx_anomaly_split[0]]), \n","                            np.asarray(idx_anomaly[idx_anomaly_split[0]:]) - idx_split[1]]\n","    print(\"Anomaly indices in the test set are {}\".format(idx_anomaly_test))\n","    \n","    if save_file:\n","        save_dir = '/content/drive/MyDrive/Colab Notebooks/Timeseries/Team_project/VAE-LSTM-for-anomaly-detection/datasets/NAB-known-anomaly/'\n","        np.savez(save_dir+dataset+'.npz', t=t, t_unit=t_unit, readings=readings, idx_anomaly=idx_anomaly,\n","                    idx_split=idx_split, training=training, test=test, train_m=train_m, train_std=train_std,\n","                    t_train=t_train, t_test=t_test, idx_anomaly_test=idx_anomaly_test)\n","        print(\"\\nProcessed time series are saved at {}\".format(save_dir+dataset+'.npz'))\n","    else:\n","        print(\"\\nProcessed time series are not saved.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q47fByHghbhr","executionInfo":{"status":"ok","timestamp":1623763871371,"user_tz":-540,"elapsed":1621,"user":{"displayName":"황보성훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQv-AFTIUw9GfCGLfL0KckPa-e7rFWhGt5tF78rQ=s64","userId":"05629785583952416700"}},"outputId":"fce9962d-6e67-4eec-f068-0c63f7dc1c85"},"source":["idx_split = [0,77875] # train(77875개)/val(18350개)\n","\n","#process_and_save_specified_dataset('fall_data', idx_split, y_scale=4, save_file=True) # train/val\n","process_and_save_specified_dataset('test_fall_data', idx_split, y_scale=4, save_file=True) # test(총 18352개)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","--> Anomalies occur at:\n","\n","Original csv file contains (90040,) timestamps.\n","Processed time series contain (90040,) readings.\n","Anomaly indices are [83875, 83876, 83877, 83878, 83879, 83880, 83881, 83882, 83883, 83884, 83885, 83886, 83887, 83888, 83889, 83890, 83891, 83892, 83893, 83894, 83895, 83896, 83897, 83898, 83899, 83900, 83901, 83902, 83903, 83904, 83905, 83906, 83907, 83908, 83909, 83910, 83911, 83912, 83913, 83914, 83915, 83916, 83917, 83918, 83919, 83920, 83921, 83922, 83923, 83924, 83925, 83926, 83927, 83928, 83929, 83930]\n","\n","Training set mean is 0.008316448094505501\n","Training set std is 0.026930146741187475\n","Anomaly indices in the test set are [6000 6001 6002 6003 6004 6005 6006 6007 6008 6009 6010 6011 6012 6013\n"," 6014 6015 6016 6017 6018 6019 6020 6021 6022 6023 6024 6025 6026 6027\n"," 6028 6029 6030 6031 6032 6033 6034 6035 6036 6037 6038 6039 6040 6041\n"," 6042 6043 6044 6045 6046 6047 6048 6049 6050 6051 6052 6053 6054 6055]\n","\n","Processed time series are saved at /content/drive/MyDrive/Colab Notebooks/Timeseries/Team_project/VAE-LSTM-for-anomaly-detection/datasets/NAB-known-anomaly/test_fall_data.npz\n"],"name":"stdout"}]}]}